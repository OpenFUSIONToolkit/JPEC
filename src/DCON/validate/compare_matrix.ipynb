{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3586d344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 11:37:13) [Clang 14.0.6 ] on darwin\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      ">>> ^C\n",
      ">>> \n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 0, in <module>\n",
      "KeyboardInterrupt\n",
      ">>> "
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33m/usr/bin/env python3\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m zhemm\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from scipy.linalg.blas import zhemm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.linalg import cho_factor, cho_solve, lu_factor, lu_solve\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "m_high = 1\n",
    "m_low = -4\n",
    "mdim = m_high - m_low + 1\n",
    "ndim = 1\n",
    "size = mdim * ndim\n",
    "\"\"\"\n",
    "... (주석) ...\n",
    "- F_bar, K_bar, G 행렬과 q 프로파일을 바이너리 파일에서 읽어 보간.\n",
    "- 최종 F, K 행렬은 히트맵 플롯 시점에 필요한 샘플에 대해서만 즉석에서 계산하여 성능 저하를 방지.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 1 & 2. 파일 읽기 관련 함수 (이전과 동일)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "\n",
    "def get_matrix_map(m, kind, n_blocks, mband_k=None, path=None):\n",
    "    if kind in ('F', 'G'):\n",
    "        for mb_test in range(m):\n",
    "            count = sum(len(range(j, min(m, j + mb_test + 1))) for j in range(m))\n",
    "            if count == n_blocks:\n",
    "                mband = mb_test\n",
    "                print(f\"[{os.path.basename(path)}] mband = {mband} (으)로 추정 (F/G).\")\n",
    "                d = {k+1: (i,j) for k, (j,i) in enumerate(((j,i) for j in range(m) for i in range(j, min(m, j+mband+1))))}\n",
    "                return d\n",
    "        raise ValueError(f\"F/G 행렬의 mband를 추정할 수 없습니다. (m={m}, n_blocks={n_blocks})\")\n",
    "    elif kind == 'K':\n",
    "        if mband_k is None: raise ValueError(\"K 행렬을 처리하려면 mband_k 값을 지정해야 합니다.\")\n",
    "        print(f\"[{os.path.basename(path)}] mband = {mband_k} (지정된 값) 사용 (K).\")\n",
    "        valid_element_count = sum(len(range(max(0, j-mband_k), min(m, j+mband_k+1))) for j in range(m))\n",
    "        if n_blocks > valid_element_count:\n",
    "            print(f\"  > 경고: 파일에 기록된 블록 수({n_blocks})가 실제 유효한 원소 수({valid_element_count})보다 많습니다.\")\n",
    "        d = {}\n",
    "        k = 0\n",
    "        for j in range(m):\n",
    "            for i in range(max(0, j - mband_k), min(m, j + mband_k + 1)):\n",
    "                k += 1\n",
    "                d[k] = (i, j)\n",
    "        return d\n",
    "    else: raise ValueError(\"kind는 'F', 'G', 'K' 중 하나여야 합니다.\")\n",
    "\n",
    "def read_bin(path, m, kind, mband_k=None):\n",
    "    all_records = []\n",
    "    with open(path, 'rb') as f:\n",
    "        while True:\n",
    "            header_bytes = f.read(4)\n",
    "            if not header_bytes: break\n",
    "            record_len = struct.unpack('<i', header_bytes)[0]\n",
    "            if record_len > 0:\n",
    "                all_records.append(np.frombuffer(f.read(record_len), dtype=np.float32))\n",
    "            else:\n",
    "                all_records.append(None)\n",
    "            f.read(4)\n",
    "    element_blocks = []\n",
    "    current_block = []\n",
    "    for rec in all_records:\n",
    "        if rec is not None: current_block.append(rec)\n",
    "        else:\n",
    "            if current_block: element_blocks.append(np.array(current_block))\n",
    "            current_block = []\n",
    "    if not element_blocks: raise ValueError(f\"파일에서 데이터 블록을 찾지 못했습니다: {path}\")\n",
    "\n",
    "    n_blocks, n_psi = len(element_blocks), element_blocks[0].shape[0]\n",
    "    psi, q_profile = element_blocks[0][:, 0], element_blocks[0][:, 1]\n",
    "    idx_map = get_matrix_map(m, kind, n_blocks, mband_k=mband_k, path=path)\n",
    "    \n",
    "    mats = np.zeros((n_psi, m, m), dtype=np.complex128)\n",
    "    for k, (i, j) in idx_map.items():\n",
    "        if k > n_blocks: continue\n",
    "        mats[:, i, j] = element_blocks[k - 1][:, 2] + 1j * element_blocks[k - 1][:, 3]\n",
    "\n",
    "    if kind in ('G'):\n",
    "        il, jl = np.tril_indices(m, -1)\n",
    "        mats[:, jl, il] = np.conj(mats[:, il, jl])\n",
    "        \n",
    "    return psi, q_profile, mats\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# 3. dedup, make_interp, plot_q_profile (이전과 동일)\n",
    "# ────────────────────────────────────────\n",
    "def dedup(psi, q, stacks):\n",
    "    uniq_psi, idx = np.unique(psi, return_index=True)\n",
    "    return uniq_psi, q[idx], {k: v[idx] for k, v in stacks.items()}\n",
    "\n",
    "def make_interp(psi, mat_stack):\n",
    "    cs_r = CubicSpline(psi, mat_stack.real, axis=0)\n",
    "    cs_i = CubicSpline(psi, mat_stack.imag, axis=0)\n",
    "    return lambda x, cr=cs_r, ci=cs_i: cr(x) + 1j * ci(x)\n",
    "\n",
    "def plot_q_profile(psi, q, q_interpolant):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(psi, q, 'o', label='Original Data Points', markersize=5)\n",
    "    psi_fine = np.linspace(psi.min(), psi.max(), 300)\n",
    "    ax.plot(psi_fine, q_interpolant(psi_fine), '-', label='Cubic Spline Interpolation')\n",
    "    ax.set(title='Safety Factor (q) Profile', xlabel='Normalized Poloidal Flux (ψ)', ylabel='Safety Factor (q)')\n",
    "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# *** REVISED *** 4. 최종 행렬의 히트맵을 그리는 함수\n",
    "# ────────────────────────────────────────\n",
    "def plot_final_heatmaps(psi_coords, M, q_interp, F_bar_interp, G_interp, K_bar_interp, nsamp=4):\n",
    "    \"\"\"\n",
    "    보간 함수들을 받아, 플롯에 필요한 psi 샘플에 대해서만 최종 행렬을 계산하고 히트맵을 그립니다.\n",
    "    \"\"\"\n",
    "    names = ['F', 'G', 'K']\n",
    "    samp = np.quantile(psi_coords, np.linspace(.05, .95, nsamp))\n",
    "    \n",
    "    fig, ax = plt.subplots(len(names), nsamp,\n",
    "                        figsize=(4.5 * nsamp, 4 * len(names)),\n",
    "                        constrained_layout=True, squeeze=False)\n",
    "    \n",
    "    I = np.identity(M.shape[0])\n",
    "\n",
    "    for c, p in enumerate(samp):\n",
    "        # --- 계산은 이 루프 안에서 즉석으로 수행됩니다 ---\n",
    "        q_val = q_interp(p)\n",
    "        Q_mat = M - q_val * I\n",
    "        \n",
    "        # 각 psi 샘플(p)에 대해 최종 행렬 계산\n",
    "        final_mats = {\n",
    "            'F': Q_mat @ F_bar_interp(p) @ Q_mat,\n",
    "            'G': G_interp(p),\n",
    "            'K': Q_mat @ K_bar_interp(p)\n",
    "        }\n",
    "        # ---------------------------------------------\n",
    "        \n",
    "        for r, n in enumerate(names):\n",
    "            mat = final_mats[n]\n",
    "            im = ax[r, c].imshow(np.abs(mat), cmap='viridis', origin='upper', aspect='equal')\n",
    "            ax[r, c].set_title(f'{n}, ψ≈{p:.3f}')\n",
    "            if r == len(names) - 1: ax[r, c].set_xlabel('j')\n",
    "            if c == 0: ax[r, c].set_ylabel('i')\n",
    "            plt.colorbar(im, ax=ax[r, c], label=f'|{n}|')\n",
    "            \n",
    "    fig.suptitle('Final F, G, K Heatmaps (Calculated On-the-fly)', y=1.03)\n",
    "    plt.show()\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# 5. 메인 스크립트\n",
    "# ────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    # --- 사용자 설정 변수 ---\n",
    "    MPERT = mdim\n",
    "    MBAND_K = MPERT - 1 \n",
    "    M_MODES = np.arange(m_low, m_high + 1) # MPERT=36일 경우, -17 ~ 18\n",
    "    \n",
    "    BASE_PATH = '/Users/seoda-eun/git/JPEC3/JPEC/src/DCON/validate'\n",
    "    \n",
    "    # --- 데이터 읽기 ---\n",
    "    files_to_read = { 'F': 'fs.bin', 'G': 'gs.bin', 'K': 'ks.bin' }\n",
    "    matrix_stacks, psi_coords, q_coords = {}, None, None\n",
    "    for name, fname in files_to_read.items():\n",
    "        path = os.path.join(BASE_PATH, fname)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"파일을 찾을 수 없습니다: {path}\"); continue\n",
    "        print(f\"파일 읽는 중: {fname} (as {'F_bar' if name=='F' else 'K_bar' if name=='K' else name})\")\n",
    "        try:\n",
    "            mband_val = MBAND_K if name == 'K' else None\n",
    "            psi, q, mat = read_bin(path, MPERT, name, mband_k=mband_val)\n",
    "            matrix_stacks[name] = mat\n",
    "            if psi_coords is None: psi_coords, q_coords = psi, q\n",
    "        except Exception as e:\n",
    "            print(f\"오류: {fname} 처리 중 문제 발생. {e}\"); import traceback; traceback.print_exc()\n",
    "\n",
    "    if not matrix_stacks:\n",
    "        print(\"데이터를 성공적으로 읽지 못했습니다. 프로그램을 종료합니다.\"); exit()\n",
    "\n",
    "    # --- 데이터 처리 및 보간 ---\n",
    "    if 'F' in matrix_stacks:\n",
    "        print(\"\\nF_bar 행렬 복원 (L·Lᴴ)...\")\n",
    "        L = np.tril(matrix_stacks['F'])                    # 하삼각(대각 포함)\n",
    "        matrix_stacks['F'] = L @ L.transpose(0, 2, 1).conj()  # F_bar = L Lᴴ\n",
    "\n",
    "    psi_coords, q_coords, matrix_stacks = dedup(psi_coords, q_coords, matrix_stacks)\n",
    "    \n",
    "    print(\"보간 함수 생성 중 (F_bar, G, K_bar, q)...\")\n",
    "    F_bar_interp = make_interp(psi_coords, matrix_stacks['F'])\n",
    "    G_interp = make_interp(psi_coords, matrix_stacks['G'])\n",
    "    K_bar_interp = make_interp(psi_coords, matrix_stacks['K'])\n",
    "    q_of_psi = CubicSpline(psi_coords, q_coords)\n",
    "    print(\"보간 함수 생성 완료.\")\n",
    "    \n",
    "    # --- 최종 행렬 계산 및 시각화 ---\n",
    "    if len(M_MODES) != MPERT:\n",
    "        raise ValueError(f\"M_MODES 배열 길이({len(M_MODES)})가 MPERT({MPERT})와 불일치.\")\n",
    "    M = np.diag(M_MODES)\n",
    "\n",
    "    # 시각화: 플롯에 필요한 4개의 샘플에 대해서만 즉석에서 계산\n",
    "    plot_q_profile(psi_coords, q_coords, q_of_psi)\n",
    "    plot_final_heatmaps(psi_coords, M, q_of_psi, F_bar_interp, G_interp, K_bar_interp, nsamp=4)\n",
    "\n",
    "    # --- 단일 psi 값에 대한 분석용 함수 (선택적 사용) ---\n",
    "    def compute_matrices(psi):\n",
    "        \"\"\"특정 psi에 대한 최종 F, G, K 행렬을 계산합니다.\"\"\"\n",
    "        I = np.identity(MPERT)\n",
    "        q_val = q_of_psi(psi)\n",
    "        Q_mat = M - q_val * I\n",
    "        \n",
    "        f_final = Q_mat @ F_bar_interp(psi) @ Q_mat\n",
    "        g_final = G_interp(psi)\n",
    "        k_final = Q_mat @ K_bar_interp(psi)\n",
    "        \n",
    "        return {'F': f_final, 'G': g_final, 'K': k_final}\n",
    "\n",
    "    print(\"\\n분석이 완료되었습니다.\")\n",
    "    print(\"`compute_matrices(psi)` 함수로 특정 psi에서의 행렬을 계산할 수 있습니다.\")\n",
    "    psi_test = 0.5\n",
    "    final_mats_at_half = compute_matrices(psi_test)\n",
    "    print(f\"예시: ψ = {psi_test} 에서의 |F_00|: {np.abs(final_mats_at_half['F'][0,0]):.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada4ecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.5.1\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/seoda-eun/anaconda3/envs/mkl_env\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2025.1.3~ --> pkgs/main::ca-certificates-2025.2.25-hecd8cb5_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620eba42",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict\n",
    "from scipy.interpolate import interp1d\n",
    "import struct\n",
    "\n",
    "class TokamakCylinderLoader:\n",
    "    \"\"\"\n",
    "    A class to read and interpolate Tokamak and Cylinder matrices (A–H, F–K).\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    load_all(psin_target)\n",
    "        Reads all Tokamak (A,B,C,D,E,H from imats; F from fs.bin; G from gs.bin; K from ks.bin)\n",
    "        and Cylinder (A,B,C,D,E,H from individual CSVs; F,G,K from diag CSV), then interpolates\n",
    "        onto psin_target.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    imats_path       : str\n",
    "        Path to tokamak 'imats.out'\n",
    "    fs_bin_path      : str\n",
    "        Path to 'fs.bin'\n",
    "    gs_bin_path      : str\n",
    "        Path to 'gs.bin'\n",
    "    ks_bin_path      : str\n",
    "        Path to 'ks.bin'\n",
    "    mpert            : int\n",
    "        mpert value used in Fortran\n",
    "    mband            : int\n",
    "        mband value used in Fortran\n",
    "    cyl_paths        : Dict[str, str]\n",
    "        Paths to cylinder A–H CSVs, keys 'A','B','C','D','E','H'\n",
    "    cyl_FGK_diag_csv : str\n",
    "        Path to 'dcon_FKG_diagonal_elements.csv'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        imats_path: str,\n",
    "        fs_bin_path: str,\n",
    "        gs_bin_path: str,\n",
    "        ks_bin_path: str,\n",
    "        mpert: int,\n",
    "        mband: int,\n",
    "        cyl_A_csv: str,\n",
    "        cyl_B_csv: str,\n",
    "        cyl_C_csv: str,\n",
    "        cyl_D_csv: str,\n",
    "        cyl_E_csv: str,\n",
    "        cyl_H_csv: str,\n",
    "        cyl_FGK_diag_csv: str\n",
    "    ):\n",
    "        self.imats_path = imats_path\n",
    "        self.fs_bin_path = fs_bin_path\n",
    "        self.gs_bin_path = gs_bin_path\n",
    "        self.ks_bin_path = ks_bin_path\n",
    "        self.mpert = mpert\n",
    "        self.mband = mband\n",
    "        self.cyl_paths = {\n",
    "            'A': cyl_A_csv,\n",
    "            'B': cyl_B_csv,\n",
    "            'C': cyl_C_csv,\n",
    "            'D': cyl_D_csv,\n",
    "            'E': cyl_E_csv,\n",
    "            'H': cyl_H_csv\n",
    "        }\n",
    "        self.cyl_FGK_diag_csv = cyl_FGK_diag_csv\n",
    "\n",
    "    # 1. read_imats_out\n",
    "    @staticmethod\n",
    "    def read_imats_out(file_path: str, names: Tuple[str, ...] = ('A','B','C','D','E','H')) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        header = lines[2].split()\n",
    "        mpsi  = int(header[2])\n",
    "        mpert = int(header[-1])\n",
    "        data  = lines[5:]\n",
    "        m1 = [int(l.split()[1]) for l in data if len(l.split()) == 15]\n",
    "        m2 = [int(l.split()[2]) for l in data if len(l.split()) == 15]\n",
    "        mi, mj   = min(m1), max(m1)\n",
    "        offset   = -mi\n",
    "        size     = mj - mi + 1\n",
    "        psi = np.zeros(mpsi + 1)\n",
    "        mats = {n: np.zeros((mpsi + 1, size, size), np.complex128) for n in names}\n",
    "        idx = {'A':0,'B':2,'C':4,'D':6,'E':8,'F':10,'G':12,'H':14}\n",
    "        for ln in data:\n",
    "            sp = ln.split()\n",
    "            if len(sp) != 15:\n",
    "                continue\n",
    "            p = float(sp[0])\n",
    "            i = int(sp[1]) + offset\n",
    "            j = int(sp[2]) + offset\n",
    "            k = int(round(p * mpsi))\n",
    "            psi[k] = p\n",
    "            nums = list(map(float, sp[3:]))\n",
    "            for nm in names:\n",
    "                r, imv = nums[idx[nm]], nums[idx[nm] + 1]\n",
    "                mats[nm][k, i, j] = r + 1j * imv\n",
    "        return psi, mats\n",
    "\n",
    "    # 2. read_vector_out + expand_vector_to_diag\n",
    "    @staticmethod\n",
    "    def read_vector_out(file_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        blocks, cur = [], []\n",
    "        for ln in Path(file_path).read_text().splitlines():\n",
    "            s = ln.strip()\n",
    "            if not s:\n",
    "                if cur:\n",
    "                    blocks.append(np.array(cur))\n",
    "                    cur = []\n",
    "                continue\n",
    "            parts = s.split()\n",
    "            if len(parts) == 4:\n",
    "                p, _, re, im = parts\n",
    "                cur.append((float(p), float(re) + 1j * float(im)))\n",
    "        if cur:\n",
    "            blocks.append(np.array(cur))\n",
    "        psi = np.array([row[0] for row in blocks[0]])\n",
    "        n_psi = len(psi)\n",
    "        n_ipert = len(blocks)\n",
    "        vec = np.empty((n_psi, n_ipert), np.complex64)\n",
    "        for i, b in enumerate(blocks):\n",
    "            vec[:, i] = b[:, 1]\n",
    "        return psi, vec\n",
    "\n",
    "    @staticmethod\n",
    "    def expand_vector_to_diag(mat_vec: np.ndarray) -> np.ndarray:\n",
    "        n_psi, n = mat_vec.shape\n",
    "        full = np.zeros((n_psi, n, n), dtype=mat_vec.dtype)\n",
    "        for k in range(n_psi):\n",
    "            np.fill_diagonal(full[k], mat_vec[k])\n",
    "        return full\n",
    "\n",
    "    # 3. read_fs_bin / read_gs_bin / read_ks_bin\n",
    "    @staticmethod\n",
    "    def read_fs_bin(\n",
    "        file_path: str,\n",
    "        mpsi: int,\n",
    "        mpert: int,\n",
    "        mband: int\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        n_ipert_fs = (mband + 1) * (2 * mpert - mband) // 2\n",
    "        n_ipert_ks = (2 * mband + 1) * mpert\n",
    "        bytes_per_ipert = (mpsi + 1) * (4 + 16 + 4) + (4 + 0 + 4)\n",
    "        total_size = Path(file_path).stat().st_size\n",
    "        if total_size % bytes_per_ipert == 0:\n",
    "            cand_ipert = total_size // bytes_per_ipert\n",
    "        else:\n",
    "            raise ValueError(f\"File size {total_size} not divisible by expected block size {bytes_per_ipert}.\")\n",
    "        if cand_ipert == n_ipert_fs:\n",
    "            n_ipert = n_ipert_fs\n",
    "        elif cand_ipert == n_ipert_ks:\n",
    "            n_ipert = n_ipert_ks\n",
    "        else:\n",
    "            n_ipert = n_ipert_fs\n",
    "\n",
    "        psi_arr = np.zeros(mpsi + 1, dtype=np.float64)\n",
    "        sqfs   = np.zeros(mpsi + 1, dtype=np.float64)\n",
    "        M      = np.zeros((n_ipert, mpsi + 1), dtype=np.complex128)\n",
    "\n",
    "        with open(file_path, 'rb') as f:\n",
    "            for ipert in range(n_ipert):\n",
    "                for ipsi in range(mpsi + 1):\n",
    "                    rec_len_bytes = f.read(4)\n",
    "                    if len(rec_len_bytes) < 4:\n",
    "                        raise EOFError(\"Unexpected EOF reading record length.\")\n",
    "                    rec_len = struct.unpack('<i', rec_len_bytes)[0]\n",
    "                    blob = f.read(4 * 4)\n",
    "                    vals = struct.unpack('<4f', blob)\n",
    "                    _ = f.read(4)\n",
    "\n",
    "                    if ipert == 0:\n",
    "                        psi_arr[ipsi] = float(vals[0])\n",
    "                        sqfs[ipsi]   = float(vals[1])\n",
    "                    M[ipert, ipsi] = float(vals[2]) + 1j * float(vals[3])\n",
    "\n",
    "                zero1 = f.read(4)\n",
    "                if not zero1:\n",
    "                    raise EOFError(\"Unexpected EOF reading blank record marker.\")\n",
    "                _ = f.read(4)\n",
    "\n",
    "        return psi_arr, sqfs, M\n",
    "\n",
    "    read_gs_bin = read_fs_bin\n",
    "    read_ks_bin = read_fs_bin\n",
    "\n",
    "    # 4. read_block_csv_matrix + read_cylinder_real_matrix\n",
    "    @staticmethod\n",
    "    def read_block_csv_matrix(file_path: str, want_imag: bool = False) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        psi_vals, blocks, cur, reading = [], [], [], None\n",
    "        for ln in Path(file_path).read_text().splitlines():\n",
    "            s = ln.strip()\n",
    "            if not s:\n",
    "                if cur:\n",
    "                    blocks.append(np.array(cur, float))\n",
    "                    cur = []\n",
    "                continue\n",
    "            if s.startswith('# psi='):\n",
    "                psi_vals.append(float(s.split('=')[1]))\n",
    "            elif s.startswith('# Real'):\n",
    "                reading = 'real'\n",
    "            elif s.startswith('# Imag'):\n",
    "                reading = 'imag'\n",
    "            elif s and not s.startswith('#'):\n",
    "                if (reading == 'imag') == want_imag:\n",
    "                    cur.append(list(map(float, s.split(','))))\n",
    "        if cur:\n",
    "            blocks.append(np.array(cur, float))\n",
    "        psi = np.array(psi_vals)\n",
    "        mats = np.stack(blocks, axis=0)\n",
    "        return psi, mats\n",
    "\n",
    "    @staticmethod\n",
    "    def read_cylinder_real_matrix(file_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        psi, real_mat = TokamakCylinderLoader.read_block_csv_matrix(file_path, want_imag=False)\n",
    "        complex_mat = real_mat.astype(np.complex128)\n",
    "        return psi, complex_mat\n",
    "\n",
    "    # 5. read_cylinder_FGK_from_diag\n",
    "    @staticmethod\n",
    "    def read_cylinder_FGK_from_diag(file_path: str) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n",
    "        df  = pd.read_csv(file_path)\n",
    "        psi = df['psi'].values\n",
    "        mats = {}\n",
    "        for key in ('F','G','K'):\n",
    "            prefix = f\"{key}_diag\"\n",
    "            cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "            diag_vals = df[cols].values\n",
    "            n_psi, m = diag_vals.shape\n",
    "            full = np.zeros((n_psi, m, m), dtype=np.complex128)\n",
    "            for k in range(n_psi):\n",
    "                np.fill_diagonal(full[k], diag_vals[k])\n",
    "            mats[key] = full\n",
    "        return psi, mats\n",
    "\n",
    "    # 6. clean_and_deduplicate_psin\n",
    "    @staticmethod\n",
    "    def clean_and_deduplicate_psin(psin: np.ndarray, mat: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        psin_rounded = np.round(psin, 8)\n",
    "        unique_vals, inv_idx = np.unique(psin_rounded, return_inverse=True)\n",
    "        m = mat.shape[1]\n",
    "        mat_out = np.zeros((len(unique_vals), m, m), dtype=mat.dtype)\n",
    "        counts = np.zeros(len(unique_vals), dtype=int)\n",
    "        for i, idx in enumerate(inv_idx):\n",
    "            mat_out[idx] += mat[i]\n",
    "            counts[idx] += 1\n",
    "        mat_out /= counts[:, None, None]\n",
    "        return unique_vals, mat_out\n",
    "\n",
    "    # 7. interpolate_matrix_over_psin\n",
    "    @staticmethod\n",
    "    def interpolate_matrix_over_psin(psin_orig: np.ndarray, mat_orig: np.ndarray, psin_target: np.ndarray) -> np.ndarray:\n",
    "        n, m, _ = mat_orig.shape\n",
    "        mat_interp = np.zeros((len(psin_target), m, m), dtype=np.complex128)\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                f = interp1d(psin_orig, mat_orig[:, i, j], kind='cubic', bounds_error=False, fill_value=\"extrapolate\")\n",
    "                mat_interp[:, i, j] = f(psin_target)\n",
    "        return mat_interp\n",
    "\n",
    "    # 8. load_all: 통합 함수\n",
    "    def load_all(self, psin_target: np.ndarray) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        result = {'tokamak': {}, 'cylinder': {}}\n",
    "\n",
    "        # --- Tokamak: A–H from imats.out ---\n",
    "        psi_imats, mats_imats = TokamakCylinderLoader.read_imats_out(self.imats_path, names=('A','B','C','D','E','H'))\n",
    "        for nm in ('A','B','C','D','E','H'):\n",
    "            psi_clean, m_clean = TokamakCylinderLoader.clean_and_deduplicate_psin(psi_imats, mats_imats[nm])\n",
    "            result['tokamak'][nm] = TokamakCylinderLoader.interpolate_matrix_over_psin(psi_clean, m_clean, psin_target)\n",
    "\n",
    "        # --- Tokamak: F from fs.bin ---\n",
    "        psi_fs, sqfs, mat_F = TokamakCylinderLoader.read_fs_bin(self.fs_bin_path, mpsi=psi_imats.size-1, mpert=self.mpert, mband=self.mband)\n",
    "        psi_fs, mat_F = TokamakCylinderLoader.clean_and_deduplicate_psin(psi_fs, mat_F)\n",
    "        result['tokamak']['F'] = TokamakCylinderLoader.interpolate_matrix_over_psin(psi_fs, mat_F, psin_target)\n",
    "\n",
    "        # --- Tokamak: G from gs.bin ---\n",
    "        psi_gs, sqgs, mat_G = TokamakCylinderLoader.read_gs_bin(self.gs_bin_path, mpsi=psi_imats.size-1, mpert=self.mpert, mband=self.mband)\n",
    "        psi_gs, mat_G = TokamakCylinderLoader.clean_and_deduplicate_psin(psi_gs, mat_G)\n",
    "        result['tokamak']['G'] = TokamakCylinderLoader.interpolate_matrix_over_psin(psi_gs, mat_G, psin_target)\n",
    "\n",
    "        # --- Tokamak: K from ks.bin ---\n",
    "        psi_ks, sqks, mat_K = TokamakCylinderLoader.read_ks_bin(self.ks_bin_path, mpsi=psi_imats.size-1, mpert=self.mpert, mband=self.mband)\n",
    "        psi_ks, mat_K = TokamakCylinderLoader.clean_and_deduplicate_psin(psi_ks, mat_K)\n",
    "        result['tokamak']['K'] = TokamakCylinderLoader.interpolate_matrix_over_psin(psi_ks, mat_K, psin_target)\n",
    "\n",
    "        # --- Cylinder: A–H from CSVs ---\n",
    "        for nm, path in self.cyl_paths.items():\n",
    "            psi_c, mat_c = TokamakCylinderLoader.read_cylinder_real_matrix(path)\n",
    "            psi_c, mat_c = TokamakCylinderLoader.clean_and_deduplicate_psin(psi_c, mat_c)\n",
    "            result['cylinder'][nm] = TokamakCylinderLoader.interpolate_matrix_over_psin(psi_c, mat_c, psin_target)\n",
    "\n",
    "        # --- Cylinder: F, G, K from diag CSV ---\n",
    "        psi_fkg, mats_fkg = TokamakCylinderLoader.read_cylinder_FGK_from_diag(self.cyl_FGK_diag_csv)\n",
    "        for nm in ('F','G','K'):\n",
    "            psi_c, mat_c = TokamakCylinderLoader.clean_and_deduplicate_psin(psi_fkg, mats_fkg[nm])\n",
    "            result['cylinder'][nm] = TokamakCylinderLoader.interpolate_matrix_over_psin(psi_c, mat_c, psin_target)\n",
    "\n",
    "        return result\n",
    "\n",
    "# ======================\n",
    "# Usage example\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 환경에 맞게 경로와 Fortran 파라미터 설정\n",
    "    loader = TokamakCylinderLoader(\n",
    "        imats_path       = \"imats.out\",\n",
    "        fs_bin_path      = \"fs.bin\",\n",
    "        gs_bin_path      = \"gs.bin\",\n",
    "        ks_bin_path      = \"ks.bin\",\n",
    "        mpert            = 6,\n",
    "        mband            = 2,\n",
    "        cyl_A_csv        = \"A_matrices.csv\",\n",
    "        cyl_B_csv        = \"B_matrices.csv\",\n",
    "        cyl_C_csv        = \"C_matrices.csv\",\n",
    "        cyl_D_csv        = \"D_matrices.csv\",\n",
    "        cyl_E_csv        = \"E_matrices.csv\",\n",
    "        cyl_H_csv        = \"H_matrices.csv\",\n",
    "        cyl_FGK_diag_csv = \"dcon_FKG_diagonal_elements.csv\"\n",
    "    )\n",
    "\n",
    "    # 2) 공통 psin 그리드 정의\n",
    "    psin_target = np.linspace(0, 1, 200)\n",
    "\n",
    "    # 3) 모든 행렬 읽고 보간\n",
    "    all_data = loader.load_all(psin_target)\n",
    "\n",
    "    # 4) 결과 출력\n",
    "    print(\"=== Tokamak matrices ===\")\n",
    "    for name, mat in all_data['tokamak'].items():\n",
    "        print(f\"{name}: {mat.shape}\")\n",
    "    print(\"\\n=== Cylinder matrices ===\")\n",
    "    for name, mat in all_data['cylinder'].items():\n",
    "        print(f\"{name}: {mat.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050349e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mkl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
